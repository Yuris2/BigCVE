{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring CVEfixes:\n",
    "- Computing some statistics on the data, and generating some diagrams and tables from CVEfixes dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3 as lite\n",
    "from sqlite3 import Error\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as tick\n",
    "import requests\n",
    "import difflib as diff\n",
    "import re \n",
    "import csv\n",
    "import ast\n",
    "%matplotlib inline\n",
    "\n",
    "# pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "def create_connection(db_file):\n",
    "    \"\"\"\n",
    "    create a connection to sqlite3 database\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = lite.connect(db_file, timeout=10)  # connection via sqlite3\n",
    "        # engine = sa.create_engine('sqlite:///' + db_file)  # connection via sqlalchemy\n",
    "        # conn = engine.connect()\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    return conn\n",
    "\n",
    "\n",
    "DATA_PATH = Path.cwd().parents[0] / 'Data'\n",
    "FIGURE_PATH = Path.cwd() / 'figures'\n",
    "RESULT_PATH = Path.cwd() / 'results'\n",
    "\n",
    "Path(DATA_PATH).mkdir(parents=True, exist_ok=True)\n",
    "Path(FIGURE_PATH).mkdir(parents=True, exist_ok=True)\n",
    "Path(RESULT_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "conn = create_connection(DATA_PATH / \"CVEfixes.db\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quering to CVEfixes database to get the parts as the separate datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An example query to retrieve all the methods of C programming language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "df_c_methods = pd.read_sql_query(\"SELECT m.name, m.signature, m.nloc, \\\n",
    "m.parameters, m.token_count, m.code, m.before_change, f.programming_language FROM method_change m, file_change f \\\n",
    "WHERE f.file_change_id=m.file_change_id AND f.programming_language='C'\", conn)\n",
    "df_c_methods.head(5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another example of query to extract all the files that have added/removed only a single statement to fix the vulnerabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "query = \"\"\"\n",
    "SELECT cv.cve_id, f.filename, f.num_lines_added, f.num_lines_deleted, f.code_before, f.code_after, cc.cwe_id \n",
    "FROM file_change f, commits c, fixes fx, cve cv, cwe_classification cc\n",
    "WHERE f.hash = c.hash \n",
    "AND c.hash = fx.hash \n",
    "AND fx.cve_id = cv.cve_id \n",
    "AND cv.cve_id = cc.cve_id \n",
    "AND f.num_lines_added<=1 \n",
    "AND f.num_lines_deleted<=1;\n",
    "\"\"\"\n",
    "java_single_line_fixes = pd.read_sql_query(query, conn)\n",
    "java_single_line_fixes.head(5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics on _CVEfixes_ data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading tables into dataframes for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "df_commit = pd.read_sql('SELECT * FROM commits', con=conn)\n",
    "df_file = pd.read_sql('SELECT * FROM file_change', con=conn)\n",
    "df_method = pd.read_sql('SELECT * FROM method_change', con=conn)\n",
    "df_cve = pd.read_sql('SELECT * FROM cve', con=conn)\n",
    "df_fixes = pd.read_sql('SELECT * FROM fixes', con=conn)\n",
    "df_cwe_class = pd.read_sql('SELECT * FROM cwe_classification', con=conn)\n",
    "df_cwe = pd.read_sql('SELECT * FROM cwe', con=conn)\n",
    "df_repo = pd.read_sql('SELECT * FROM repository', con = conn)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 major projects that have contributed most of the vulnerability data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "commit_freq_query = \"\"\"\n",
    "SELECT fx.repo_url as commit_project, count(fx.hash) as commit_count\n",
    "FROM commits c, fixes fx\n",
    "WHERE fx.hash=c.hash\n",
    "GROUP BY fx.repo_url\n",
    "ORDER BY commit_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "file_freq_query = \"\"\"\n",
    "SELECT fx.repo_url as file_project, count(f.file_change_id) as file_count \n",
    "FROM commits c, fixes fx, file_change f\n",
    "WHERE fx.hash=c.hash\n",
    "AND c.hash = f.hash\n",
    "GROUP BY fx.repo_url\n",
    "ORDER BY file_count DESC;\n",
    "\"\"\"\n",
    "method_freq_query = \"\"\"\n",
    "SELECT fx.repo_url as method_project, count(m.method_change_id) as method_count \n",
    "FROM commits c, fixes fx, file_change f, method_change m\n",
    "WHERE fx.hash=c.hash\n",
    "AND c.hash = f.hash\n",
    "AND f.file_change_id = m.file_change_id\n",
    "GROUP BY fx.repo_url\n",
    "ORDER BY method_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "df_commit_freq = pd.read_sql_query(commit_freq_query, con=conn)\n",
    "df_file_freq = pd.read_sql_query(file_freq_query, con=conn)\n",
    "df_method_freq = pd.read_sql_query(method_freq_query, con=conn)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ordering the projects on the basis of number of commits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "df_meta = df_commit_freq.merge(df_file_freq, \n",
    "                               left_on='commit_project', \n",
    "                               right_on='file_project').merge(df_method_freq, \n",
    "                                                             left_on='commit_project', \n",
    "                                                             right_on='method_project')\n",
    "df_meta = df_meta.replace(np.nan,0)\n",
    "df_meta['commit_project'] = df_meta['commit_project'].str.split('/').str[-1]\n",
    "df_meta = df_meta.drop(['file_project','method_project'], axis=1)\n",
    "df_meta[['commit_count','file_count', 'method_count']] = df_meta[['commit_count','file_count', 'method_count']].astype(int)\n",
    "df_meta=df_meta.sort_values(by=['commit_count','file_count','method_count'], ascending=False)\n",
    "df_meta.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordering the projects on the basis of #commits, #files and #methods separately in a table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "df_merged = pd.concat([df_commit_freq, df_file_freq], axis=1)\n",
    "df_merged = pd.concat([df_merged, df_method_freq], axis=1)\n",
    "df_merged = df_merged.replace(np.nan, 0)\n",
    "df_merged['commit_project'] = df_merged['commit_project'].str.split('/').str[-1]\n",
    "df_merged['file_project'] = df_merged['file_project'].str.split('/').str[-1]\n",
    "df_merged['method_project'] = df_merged['method_project'].str.split('/').str[-1]\n",
    "\n",
    "df_merged[['commit_count','file_count', 'method_count']] = df_merged[['commit_count','file_count', 'method_count']].astype(int)\n",
    "df_merged = df_merged.replace('_','-', regex=True)\n",
    "\n",
    "df_merged.head(10).to_csv(RESULT_PATH / 'vul_projects_10.csv', index=False)\n",
    "df_merged.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of CVEs and CWEs on top 10 major projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "cve_freq_query = \"\"\"\n",
    "SELECT fx.repo_url AS projects, count(DISTINCT fx.cve_id) AS cve_count, count(DISTINCT cc.cwe_id) as cwe_count\n",
    "FROM fixes fx, cve cv, cwe_classification cc\n",
    "WHERE fx.cve_id=cv.cve_id\n",
    "AND cv.cve_id=cc.cve_id\n",
    "GROUP by projects \n",
    "ORDER BY cve_count DESC;\n",
    "\"\"\"\n",
    "df_cve_cwe = pd.read_sql(cve_freq_query, con=conn)\n",
    "df_cve_cwe_urls = df_cve_cwe.copy()\n",
    "df_cve_cwe['projects']= df_cve_cwe['projects'].str.split('/').str[-1]\n",
    "df_cve_cwe = df_cve_cwe.replace('_','-', regex=True)\n",
    "df_cve_cwe.head(10).to_csv(RESULT_PATH / 'dataset_summary_cve_cwe.csv', index=False)\n",
    "df_cve_cwe.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of CWEs present at file- and method level data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "cwe_count_query = \"\"\"\n",
    "SELECT cc.cwe_id as CWE, cw.cwe_name as description, count(DISTINCT cc.cve_id) cve_count,  count(DISTINCT c.hash) as commit_count, count(DISTINCT f.file_change_id) file_count, count(DISTINCT m.method_change_id) method_count\n",
    "FROM cve cv\n",
    "JOIN cwe_classification cc ON cv.cve_id=cc.cve_id\n",
    "JOIN cwe cw ON cc.cwe_id=cw.cwe_id\n",
    "JOIN fixes fx ON cv.cve_id=fx.cve_id\n",
    "JOIN commits c ON fx.hash=c.hash\n",
    "LEFT JOIN file_change f ON c.hash= f.hash\n",
    "LEFT JOIN method_change m ON f.file_change_id=m.file_change_id\n",
    "GROUP BY cc.cwe_id\n",
    "ORDER BY cve_count DESC;\n",
    "\"\"\"\n",
    "df_cwe_result = pd.read_sql(cwe_count_query, con=conn)\n",
    "df_cwe_result = df_cwe_result.sort_values(by=['cve_count'], ascending=False)\n",
    "df_cwe_result = df_cwe_result.replace('\"','', regex=True).replace(\"'\",'', regex=True).replace(',','', regex=True)\n",
    "df_cwe_result[['CWE','description','cve_count','commit_count','file_count']].head(10).to_csv(RESULT_PATH / 'cwe_summary.csv', index=False)\n",
    "print('# CWEs: ' + str(df_cwe_result.CWE.nunique()))\n",
    "df_cwe_result.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The proportion of the top 10 major projects at different granular levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "percent_10_cve = (df_cve_cwe.cve_count.head(10).sum()/df_cve.cve_id.nunique())*100\n",
    "percent_10_commit = (df_merged.commit_count.head(10).sum()/df_merged.commit_count.sum())*100\n",
    "percent_10_file = df_merged.file_count.head(10).sum()/df_file.file_change_id.nunique()*100\n",
    "percent_10_method = df_merged.method_count.head(10).sum()/df_method.method_change_id.nunique()*100\n",
    "\n",
    "# CWEs proportion 10 major projects out of the total CWEs based in file data:\n",
    "# percent_10_cwe_cve = (df_cwe_result['cve_count'].head(10).sum()/df_cve.cve_id.nunique())*100\n",
    "percent_10_cwe_cve = (df_cwe_result['cve_count'].head(10).sum()/df_cve.cve_id.count())*100\n",
    "\n",
    "percent_10_cwe_commit = (df_cwe_result['commit_count'].head(10).sum()/len(df_commit))*100\n",
    "\n",
    "#percent_10_cwe_file = (df_cwe_result['file_count'].head(10).sum()/df_file.file_change_id.nunique())*100\n",
    "percent_10_cwe_file = (df_cwe_result['file_count'].head(10).sum()/df_file.file_change_id.count())*100\n",
    "percent_10_cwe_method = (df_cwe_result['method_count'].head(10).sum()/df_method.method_change_id.count())*100\n",
    "\n",
    "print('Proportion of 10 major projects out of the total projects at different granular levels:')\n",
    "print('% CVEs: ', percent_10_cve.round(2))\n",
    "print('% commits: ', percent_10_commit.round(2))\n",
    "print('% files: ', percent_10_file.round(2))\n",
    "print('% method: ',percent_10_method.round(2))\n",
    "\n",
    "print('\\n% CWEs at CVEs: ',percent_10_cwe_cve.round(2))\n",
    "print('% CWEs at Commits: ',percent_10_cwe_commit.round(2))\n",
    "print('% CWEs at files: ',percent_10_cwe_file.round(2))\n",
    "print('% CWEs at methods ',percent_10_cwe_method.round(2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The summary of _CVEfixes_ database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "data_summary = {\n",
    "'CVEs': df_fixes.cve_id.nunique(),\n",
    "'CWEs': df_cwe_result.CWE.nunique(),\n",
    "'projects':df_merged.commit_project.count(),\n",
    "'commits': df_commit.hash.nunique(),           \n",
    "'files': df_file.file_change_id.nunique(),\n",
    "'methods': df_method.method_change_id.count()\n",
    "}\n",
    "print('#CVEs registered in CVE database : ' + str(df_cve.cve_id.nunique()))\n",
    "print('#commits registered in CVE database : ' + str(df_fixes.hash.nunique()))\n",
    "print('#projects registered in CVE database : ' + str(df_fixes.repo_url.nunique()))\n",
    "print(\"#programming languages/file formats: \" + str(df_file.programming_language.value_counts().count()-1))\n",
    "\n",
    "pd.DataFrame([data_summary]).to_csv(RESULT_PATH / 'dataset_summary.csv', index=False)\n",
    "pd.DataFrame([data_summary])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting of the CVSS severity scores of all CVE records using different diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "def show_plot(plot_type, df_plot, x_label, y_label):\n",
    "    df_plot = df_plot.astype(float)\n",
    "    fig, axs = plt.subplots()\n",
    "    if plot_type=='boxplot':\n",
    "        ax = sns.boxplot(data=df_plot, ax=axs, orient='h')\n",
    "    if plot_type=='violinplot':\n",
    "        ax = sns.violinplot(data=df_plot, ax=axs, orient='h')\n",
    "    axs.yaxis.grid(True)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.yticks(rotation=40)\n",
    "    fig.tight_layout()\n",
    "    return fig,axs"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "df_cvss = df_cve.dropna()\n",
    "df_cvss = df_cvss[df_cvss.cvss3_base_score!='nan']\n",
    "df_cvss=df_cvss[['cvss3_base_score','cvss2_base_score','exploitability_score','impact_score']].reset_index(drop=True)\n",
    "\n",
    "fig,axs = show_plot('boxplot', df_cvss, 'Severity Scores', 'Measures')\n",
    "fig,axs = show_plot('violinplot', df_cvss, 'Severity Scores', 'Measures')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting of the average CVSS severity scores of all the reported projects  in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "score_query = \"\"\"\n",
    "SELECT fx.repo_url AS projects,\n",
    "    count(fx.cve_id) AS cve_count,\n",
    "    AVG(NULLIF(v.cvss3_base_score,0)) AS avg_cvss_v3_score, \n",
    "    AVG(NULLIF(v.cvss2_base_score,0)) AS avg_cvss_v2_score, \n",
    "    AVG(NULLIF(v.exploitability_score,0)) AS avg_exploitability_score, \n",
    "    AVG(NULLIF(v.impact_score,0)) AS avg_impact_score\n",
    "FROM fixes fx, cve v\n",
    "WHERE fx.cve_id = v.cve_id\n",
    "GROUP BY projects\n",
    "ORDER BY cve_count DESC;\n",
    "\"\"\"\n",
    "df_score = pd.read_sql(score_query, conn)\n",
    "df_score = df_score.round(2)\n",
    "#df_score['projects'] = df_score.projects.str.split('/').str[-1]\n",
    "df_score.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the statistics on the days to fix vulnerabilities of each project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "def dates_diff(commit_date, publish_date):\n",
    "    pyear, pmonth, pday = publish_date.split('-')\n",
    "    publish_date = date(int(pyear), int(pmonth), int(pday.split('T')[0]))\n",
    "    \n",
    "    cyear,cmonth,cday  = commit_date.split(' ')[0].split('-')\n",
    "    commit_date = date(int(cyear), int(cmonth), int(cday))\n",
    "\n",
    "    diff_days = abs(commit_date - publish_date).days\n",
    "    return round(diff_days, 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "# df_dif_days = pd.merge(df_project, df_cve, on='cve_id')\n",
    "# df_dif_days = pd.merge(dfc, df_dif_days, on='hash')\n",
    "\n",
    "fix_days_query = \"\"\"\n",
    "SELECT fx.repo_url as project, published_date, committer_date FROM cve cv, fixes fx, commits c\n",
    "WHERE cv.cve_id=fx.cve_id\n",
    "AND fx.hash=c.hash\n",
    "\"\"\"\n",
    "df_fix_days = pd.read_sql(fix_days_query, conn)\n",
    "#df_fix_days['project'] = df_fix_days.project.str.split('/').str[-1]\n",
    "\n",
    "\n",
    "df_date = df_fix_days[['project','published_date','committer_date']].copy()\n",
    "df_date[\"mean_days_to_fix\"] = df_date.apply(lambda x: dates_diff(x.committer_date, x.published_date), axis=1)\n",
    "# df_date = df_date.groupby('project', as_index=False)['mean_days_to_fix'].mean().sort_values(by=['mean_days_to_fix'], ascending=False, na_position='first').reset_index(drop=True)\n",
    "df_date = df_date.groupby('project', as_index=False).agg({'mean_days_to_fix': ['mean','median','max','min']})\n",
    "df_date.reset_index(drop=True)\n",
    "df_date = df_date.round(3)\n",
    "df_date.columns = ['project','mean_days_to_fix','median_days_to_fix', 'max_days_to_fix','min_days_to_fix']\n",
    "df_date.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding avg_days_to_fix and cwe_count to the severity_summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "# adding cwe_count to the table\n",
    "df_score1=df_score.drop('cve_count', axis=1)\n",
    "\n",
    "df_score_all = pd.merge(df_score1, df_cve_cwe_urls, on=\"projects\")\n",
    "df_score_all.rename(columns={'cve_project':'projects'}, inplace=True)\n",
    "\n",
    "# adding average days to fix vulnerability column - avg_days_to_fix\n",
    "df_score_all = pd.merge(df_score_all, df_date, left_on='projects', right_on = 'project', how='left').drop(columns=['project'], axis=1)\n",
    "df_score_all = np.round(df_score_all, decimals=3)\n",
    "df_score_all['projects'] = df_score_all.projects.str.split('/').str[-1]\n",
    "\n",
    "df_score_all = df_score_all.sort_values(by=['cve_count'], ascending=False)\n",
    "df_score_all.to_csv(RESULT_PATH / 'severity_summary.csv', index=False)\n",
    "df_score_all.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting overall severity scores of the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "df_sev_plot = df_score[['avg_cvss_v2_score', 'avg_cvss_v3_score', 'avg_exploitability_score', 'avg_impact_score']]\n",
    "\n",
    "fig, axs = show_plot('violinplot', df_sev_plot, 'metric score', 'vulnerability severity measures')\n",
    "axs.set_yticklabels(('avg $CVSS_{v2}$ base','avg $CVSS_{v3}$ base','avg exploitability','avg impact'))\n",
    "fig.savefig(FIGURE_PATH / 'severity_violin.pdf')\n",
    "\n",
    "fig, axs = show_plot('boxplot', df_sev_plot, 'metric score', 'vulnerability severity measures')\n",
    "axs.set_yticklabels(('avg $CVSS_{v2}$ base','avg $CVSS_{v3}$ base','avg exploitability','avg impact'))\n",
    "fig.savefig(FIGURE_PATH / 'severity_boxplot.pdf')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting dmm_complexity of the commits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) DMM scores grouped by projects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "avg_dmm_query = \"\"\"\n",
    "SELECT repo_url AS projects,\n",
    "    AVG(NULLIF(dmm_unit_size,0)) AS avg_unit_size,\n",
    "    AVG(NULLIF(dmm_unit_complexity, 0)) AS avg_unit_complexity, \n",
    "    AVG(NULLIF(dmm_unit_interfacing, 0)) AS avg_unit_interfacing\n",
    "FROM commits\n",
    "GROUP BY projects;\n",
    "\"\"\"\n",
    "df_avg_dmm = pd.read_sql(avg_dmm_query, conn)\n",
    "df_avg_dmm = df_avg_dmm.round(2)\n",
    "df_avg_dmm['avg_unit_score'] = (df_avg_dmm.avg_unit_size + df_avg_dmm.avg_unit_complexity + df_avg_dmm.avg_unit_interfacing) / 3\n",
    "df_avg_dmm['projects'] = df_avg_dmm.projects.str.split('/').str[-1]\n",
    "\n",
    "plt.ion()\n",
    "fig, axs = show_plot('violinplot', df_avg_dmm[['avg_unit_size', 'avg_unit_complexity',\n",
    "       'avg_unit_interfacing', 'avg_unit_score']], 'metric score', 'delta maintainability metrics')\n",
    "axs.set_xticks(np.arange(0.0, 1.2, 0.2))\n",
    "axs.set_yticklabels(('avg unit size','avg unit complexity','avg unit interfacing','avg DMM score'))\n",
    "fig.savefig(FIGURE_PATH / 'dmm_avg_complexity_plot.pdf')\n",
    "df_avg_dmm.head(15)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "source": [
    "print('Proportion of projects with above average risk code changes = ', \n",
    "      len(df_avg_dmm[df_avg_dmm.avg_unit_score<0.5])/len(df_avg_dmm)*100)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) DMM scores of all the commits: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "df_dmmcom = df_commit[['dmm_unit_size','dmm_unit_complexity','dmm_unit_interfacing']]\n",
    "df_dmmcom = df_dmmcom.replace(\"None\", value=np.nan).dropna().astype(float)\n",
    "df_dmmcom.columns = df_dmmcom.columns.str.replace(r\"dmm_\", \"\")\n",
    "df_dmmcom['unit_score'] = (df_dmmcom.unit_size + df_dmmcom.unit_complexity + df_dmmcom.unit_interfacing) / 3\n",
    "\n",
    "fig,axs = show_plot('violinplot', df_dmmcom, 'score', 'DMM metrics')\n",
    "fig.savefig(FIGURE_PATH / 'dmm_complexity_plot.pdf')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "print('Proportion of individual above average risk code changes = ', \n",
    "      len(df_dmmcom[df_dmmcom.unit_score<0.5])/len(df_dmmcom)*100)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "sns.set(font_scale=1.4)\n",
    "\n",
    "def reformat_large_tick_values(tick_val, pos):\n",
    "    \"\"\"\n",
    "    Turns large tick values (in the billions, millions and thousands) such as 4500 into 4.5K and also appropriately turns 4000 into 4K (no zero after the decimal).\n",
    "    \"\"\"\n",
    "    if tick_val >= 1000000000:\n",
    "        val = round(tick_val/1000000000, 1)\n",
    "        new_tick_format = '{:}B'.format(val)\n",
    "    elif tick_val >= 1000000:\n",
    "        val = round(tick_val/1000000, 1)\n",
    "        new_tick_format = '{:}M'.format(val)\n",
    "    elif tick_val >= 1000:\n",
    "        val = round(tick_val/1000, 1)\n",
    "        new_tick_format = '{:}K'.format(val)\n",
    "    elif tick_val < 1000:\n",
    "        new_tick_format = round(tick_val, 1)\n",
    "    else:\n",
    "        new_tick_format = tick_val\n",
    "\n",
    "    # make new_tick_format into a string value\n",
    "    new_tick_format = str(new_tick_format)\n",
    "    \n",
    "    # code below will keep 4.5M as is but change values such as 4.0M to 4M since that zero after the decimal isn't needed\n",
    "    index_of_decimal = new_tick_format.find(\".\")\n",
    "    \n",
    "    if index_of_decimal != -1:\n",
    "        value_after_decimal = new_tick_format[index_of_decimal+1]\n",
    "        if value_after_decimal == \"0\":\n",
    "            # remove the 0 after the decimal point since it's not needed\n",
    "            new_tick_format = new_tick_format[0:index_of_decimal] + new_tick_format[index_of_decimal+2:]\n",
    "            \n",
    "    return new_tick_format"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "source": [
    "print(df_file.programming_language.value_counts())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "# at file level\n",
    "ax = df_file.programming_language.value_counts().head(15).plot.bar(\n",
    "    x = 'programming_language', y = 'file_count', align='center', legend=False, width=0.8, rot=60, figsize=(7,5),fontsize=14)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005), rotation=45, fontsize=12)\n",
    "    \n",
    "ax.yaxis.set_major_formatter(tick.FuncFormatter(reformat_large_tick_values));\n",
    "ax.set_xlabel(\"programming languages\")\n",
    "ax.set_ylabel(\"# files\")\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.savefig(FIGURE_PATH / 'file_pl_bar.pdf')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "# proportion of PHP and C\n",
    "total = df_file['programming_language'].value_counts().sum()\n",
    "pl = df_file[df_file['programming_language'].isin(['PHP','C'])].value_counts().sum()\n",
    "pl_percent = pl/total*100\n",
    "pl_percent"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "# at method level\n",
    "pl_query = \"\"\"\n",
    "SELECT f.programming_language, count(DISTINCT f.file_change_id) AS file_count, count(DISTINCT m.method_change_id) AS method_count\n",
    "from file_change f, method_change m\n",
    "WHERE f.file_change_id=m.file_change_id\n",
    "GROUP BY f.programming_language\n",
    "ORDER BY method_count DESC;\n",
    "\"\"\"\n",
    "df_pl = pd.read_sql_query(pl_query, conn)\n",
    "# dfm_pl = filterPL(dfm)  # replaced by guesslang API\n",
    "fig, ax2 = plt.subplots() \n",
    "ax2 = df_pl.sort_values(by=['method_count'], ascending=False)[['programming_language','method_count']].head(15).plot.bar(\n",
    "    x = 'programming_language', ax=ax2, y = 'method_count', legend=False, align='center', width=0.8, rot=90, figsize=(7,5),fontsize=14)\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005), rotation=45, fontsize=12)\n",
    "\n",
    "ax2.yaxis.set_major_formatter(tick.FuncFormatter(reformat_large_tick_values));\n",
    "ax2.set_xlabel(\"programming languages\")\n",
    "ax2.set_ylabel(\"# methods\")\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "fig.savefig(FIGURE_PATH / 'method_pl_bar.pdf')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (At file level) Getting all the files with single (or few) lines modification for fixing the vulnerabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Option 1: adding two columns diff_added and diff_deleted from diff_parsed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "df_diff = df_file[df_file.programming_language=='C'].copy()\n",
    "df_diff['diff_added'] = df_diff.apply(lambda row: ast.literal_eval(row.diff_parsed)['added'], axis=1)\n",
    "df_diff['diff_deleted'] = df_diff.apply(lambda row: ast.literal_eval(row.diff_parsed)['deleted'], axis=1)\n",
    "df_diff = df_diff.reset_index(drop=True)\n",
    "df_diff.head(5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Option 2: getting the added and removed statements (an alternative method without 'diff_parsed' column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "import difflib\n",
    "\n",
    "def to_diff_file(old_str, new_str):\n",
    "    \"\"\"\n",
    "    produces a diff file comparing two files/methods.\n",
    "    \"\"\"\n",
    "    diff = difflib.ndiff(old_str.splitlines(1), new_str.splitlines(1))\n",
    "    result = '\\n'.join(diff)\n",
    "    return result\n",
    "\n",
    "\n",
    "def separate_diff(diff):\n",
    "    \"\"\"\n",
    "    :returns Dictionary of added and removed statements along with line number.\n",
    "    \"\"\"\n",
    "    lines = diff.split(\"\\n\")\n",
    "    added = []  # List[Tuple[int, str]]\n",
    "    deleted = []  # List[Tuple[int, str]]\n",
    "    count_deletions = 0\n",
    "    count_additions = 0\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        count_deletions += 1\n",
    "        count_additions += 1\n",
    "\n",
    "        if line.startswith(\"-\"):\n",
    "            deleted.append((count_deletions, line[1:]))\n",
    "            count_additions -= 1\n",
    "\n",
    "        if line.startswith(\"+\"):\n",
    "            added.append((count_additions, line[1:]))\n",
    "            count_deletions -= 1\n",
    "\n",
    "        if line == r\"\\ No newline at the end of file\":\n",
    "            count_deletions -= 1\n",
    "            count_additions -= 1\n",
    "\n",
    "    return added, deleted"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "df_diff = df_diff[(df_diff.num_lines_added<='1') & (df_diff.num_lines_deleted<='1')].reset_index() # you can change the value 1 with the number of lines to be considered.\n",
    "print('Number of files with single line modification = ' + str(len(df_diff['diff'])))\n",
    "\n",
    "# added two columns 'vul' and 'patch' in the dataframe. \n",
    "df_diff['vul'] = None\n",
    "df_diff['patch'] = None\n",
    "\n",
    "for i in range(len(df_diff['diff'])):\n",
    "    lines = df_diff['diff'][i].splitlines()\n",
    "    for line in lines:\n",
    "        if(line[0]=='-'):\n",
    "            df_diff.loc[i, 'vul'] = line[1:].strip() # the old line refers the 'vulnerability' line.\n",
    "        if(line[0]=='+'):\n",
    "            df_diff.loc[i, 'patch'] = line[1:].strip() # newly added line as a patch/fix  line.\n",
    "df_diff.head(5) # you will get two last columns\n",
    "# 'diff_parsed' column can also be used to get this result."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "query = \"\"\"\n",
    "SELECT cv.cve_id, f.filename, f.num_lines_added, f.num_lines_deleted, f.code_before, f.code_after, cc.cwe_id\n",
    "FROM file_change f, commits c, fixes fx, cve cv, cwe_classification cc\n",
    "WHERE f.hash = c.hash\n",
    "AND c.hash = fx.hash\n",
    "AND fx.cve_id = cv.cve_id\n",
    "AND cv.cve_id = cc.cve_id\n",
    "AND f.num_lines_added<=1\n",
    "AND f.num_lines_deleted<=1\n",
    "AND f.programming_language='C';\n",
    "\"\"\"\n",
    "c_single_line_fixes = pd.read_sql_query(query, conn)\n",
    "c_single_line_fixes.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (At method level) Getting added and deleted statements from diff method for fixing the vulnerability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the diff file from vulnerable/old method and fix/new/modified method with the same method name of the file.\n",
    "- Separating the modified statements into diff_added and diff_deleted statements.\n",
    "- Making a dataset with diff_added, diff_deleted and vul_type columns.\n",
    "\n",
    "(the generate dataset can be used for predicting patches for the vulnerabilities at method abstraction level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "def to_diff_file(str1, str2):\n",
    "    import difflib\n",
    "    diff = difflib.ndiff(str1.splitlines(1), str2.splitlines(1))\n",
    "    result = ''.join(diff)\n",
    "    return result"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "def to_diff_dict(str1):\n",
    "    lines = str1.splitlines()\n",
    "    diff_dict = {}\n",
    "    added_lines = []\n",
    "    deleted_lines = []\n",
    "    for line in lines:\n",
    "        if(line[0]=='+'):\n",
    "            added_lines.append(line[1:].strip())\n",
    "        if(line[0]=='-'):\n",
    "            deleted_lines.append(line[1:].strip())\n",
    "\n",
    "    diff_dict = {'added':added_lines, 'deleted':deleted_lines}\n",
    "    return diff_dict"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "def separate_diff_method(diff_str):\n",
    "    \"\"\"returns a string of added statements and deleted statements \"\"\"\n",
    "    res = ast.literal_eval(diff_str)\n",
    "    added_lines = []\n",
    "    deleted_lines =[]\n",
    "    for i in res['added']:\n",
    "        added_lines.append(i.strip())\n",
    "\n",
    "    for i in res['deleted']:\n",
    "        deleted_lines.append(i.strip())\n",
    "\n",
    "    added_str = ' '.join(added_lines) # the statements are seperated by whitespaces instead of new lines\n",
    "    deleted_str = ' '.join(deleted_lines)\n",
    "    return added_str, deleted_str"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "def separate_diff(diff_str):\n",
    "    \"\"\"returns a string of added statements and deleted statements \"\"\"\n",
    "    import ast\n",
    "    res = ast.literal_eval(diff_str)\n",
    "    added_lines = []\n",
    "    deleted_lines =[]\n",
    "    for i in res['added']:\n",
    "        if type(i)==tuple:\n",
    "            added_lines.append(i[1].strip())\n",
    "        else:\n",
    "            added_lines.append(i.strip())\n",
    "\n",
    "    for i in res['deleted']:\n",
    "        if type(i)==tuple:\n",
    "            deleted_lines.append(i[1].strip())\n",
    "        else:\n",
    "            deleted_lines.append(i.strip())\n",
    "\n",
    "    added_str = ' '.join(added_lines) # the statements are seperated by whitespaces instead of new lines\n",
    "    deleted_str = ' '.join(deleted_lines)\n",
    "    return added_str, deleted_str"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "source": [
    "# adding two columns diff_added and diff_deleted to the dataframe\n",
    "\n",
    "diff_query =\"\"\"\n",
    "SELECT f.programming_language, f.file_change_id, m.name, m.code, m.before_change\n",
    "from file_change f, method_change m\n",
    "WHERE m.file_change_id=f.file_change_id\n",
    "AND f.programming_language='C'\n",
    "\"\"\"\n",
    "diff_method = pd.read_sql_query(diff_query, conn)\n",
    "#diff_method = diff_method[diff_method.programming_language=='C'].reset_index(drop=True)\n",
    "diff_result = pd.DataFrame(columns=['diff_added', 'diff_deleted'])\n",
    "\n",
    "for i in range(0, len(diff_method)-1, 2):\n",
    "    if str(diff_method['file_change_id'].iloc[i]) == str(diff_method['file_change_id'].iloc[i+1]) \\\n",
    "    and str(diff_method['name'].iloc[i]) == str(diff_method['name'].iloc[i+1]):   \n",
    "        diff_file = to_diff_file(diff_method.code[i], diff_method.code[i+1])\n",
    "        diff_dict = to_diff_dict(diff_file)\n",
    "        added, deleted = separate_diff(str(diff_dict))\n",
    "        diff_result = diff_result.append({'diff_added': added, \n",
    "                                          'diff_deleted': deleted}, ignore_index=True)\n",
    "diff_result.head(5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
